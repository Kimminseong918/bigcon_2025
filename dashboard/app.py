from __future__ import annotations
from pathlib import Path
import io, os, json, datetime, textwrap
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import requests  # â† ì›ê²©(Drive) íŒŒì¼ ë¡œë“œë¥¼ ìœ„í•´ ì¶”ê°€

# (ì„ íƒ) Gemini
try:
    import google.generativeai as genai
    _HAS_GEMINI = True
except Exception:
    _HAS_GEMINI = False

try:
    from streamlit.runtime.secrets import StreamlitSecretNotFoundError
except Exception:
    class StreamlitSecretNotFoundError(Exception):
        pass

# -------------------- ê²½ë¡œ --------------------
# === Google Drive ë°ì´í„° ìë™ ë‹¤ìš´ë¡œë“œ (ë°°í¬ ì „ í•„ìˆ˜) ===
import re

def _gdrive_id_from_link(url: str) -> str | None:
    m = re.search(r"/d/([a-zA-Z0-9_-]{20,})/", url)
    return m.group(1) if m else None

def _download_gdrive_file(file_id: str, out_path: Path) -> bool:
    try:
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        with requests.get(url, stream=True, timeout=30) as r:
            r.raise_for_status()
            with open(out_path, "wb") as f:
                for chunk in r.iter_content(chunk_size=1<<20):
                    if chunk: f.write(chunk)
        return True
    except Exception as e:
        st.warning(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {out_path.name} ({e})")
        return False

def ensure_outputs_files():
    """Drive ë§í¬ì—ì„œ outputs íŒŒì¼ ìë™ í™•ë³´"""
    OUT.mkdir(parents=True, exist_ok=True)
    files = {
        "merged_indices_monthly.parquet": "https://drive.google.com/file/d/1-iPvmfHz3mjhRe95XEoB17Ja0S_zulJm/view?usp=drive_link",
        "predictions_latest_both_delta.parquet": "https://drive.google.com/file/d/1qInDALlRx25MlShIL4yT4GTiqO-qmSWd/view?usp=drive_link",
        "predictions_latest_both_delta_named.parquet": "https://drive.google.com/file/d/1oDGLLAtPhvweruKWq2x9DTHC_LSyLG34/view?usp=drive_link",
    }
    for fname, url in files.items():
        path = OUT / fname
        if path.exists() and path.stat().st_size > 0:
            continue
        fid = _gdrive_id_from_link(url) or url
        _download_gdrive_file(fid, path)

ensure_outputs_files()

THIS = Path(__file__).resolve()
APP_DIR = THIS.parent
ROOT = APP_DIR.parent
OUT = ROOT / "outputs"

named_candidate = OUT / "predictions_latest_both_delta_named.parquet"
FILE_PRED   = named_candidate if named_candidate.exists() else (OUT / "predictions_latest_both_delta.parquet")
FILE_MERGED = OUT / "merged_indices_monthly.parquet"
FILE_MAPCSV = OUT / "big_data_set1_f.csv"

FILE_ALERTS = OUT / "signals_alerts_delta.csv"
FILE_SIGREC = OUT / "signals_recent_delta.csv"

POLICY_XLSX = OUT / "ì •ì±…ì§€ì›ê´€ë ¨ë§¤í•‘_251022.xlsx"
LOG_DIR = OUT / "ai_logs"
LOG_DIR.mkdir(parents=True, exist_ok=True)
LOG_PATH = LOG_DIR / "ai_explanation_log.jsonl"

# -------------------- UI/ìŠ¤íƒ€ì¼ --------------------
st.set_page_config(page_title="AI ê¸°ë°˜ íì—… ì¡°ê¸°ê²½ë³´ í”Œë«í¼", layout="wide")

st.markdown("""
<style>
.block-container { padding-top: 1.2rem !important; padding-bottom: 1.8rem !important; }
h1.app-title{ font-size: 32px; font-weight: 900; line-height: 1.36; margin: .1rem 0 .8rem 0;
  white-space: normal; word-break: keep-all; overflow: visible; }
.element-container, .js-plotly-plot, .plot-container{ overflow: visible !important; }
.badge{display:inline-block;padding:.2rem .5rem;border-radius:8px;font-size:12px;font-weight:800}
.badge-red{background:rgba(239,68,68,.18);color:#ef4444}
.badge-amber{background:rgba(245,158,11,.18);color:#f59e0b}
.badge-emerald{background:rgba(16,185,129,.18);color:#10b981}
.small{font-size:12px;opacity:.75}
hr{border:0;height:1px;background:rgba(120,120,120,.2);margin:8px 0 14px;}
.caption-note{font-size:13px; opacity:.92; margin-top:-4px; line-height:1.5}
.caption-list{font-size:13px; opacity:.92; margin:.2rem 0 1rem 0; padding-left:1.1rem}
.caption-list li{margin:.08rem 0}
.callout{font-size:13px; opacity:.9; margin:-8px 0 8px 0}
.card{border:1px solid rgba(120,120,120,.25); padding:.8rem 1rem; border-radius:10px; background:rgba(250,250,250,.65)}
.card h4{margin:.1rem 0 .2rem 0; font-size:14px}
.card p{margin:.2rem 0}
.kbd{padding:.05rem .35rem;border-radius:4px;border:1px solid rgba(120,120,120,.45); font-size:12px}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1 class='app-title'>ğŸ˜€ AI ê¸°ë°˜ íì—… ì¡°ê¸°ê²½ë³´ í”Œë«í¼</h1>", unsafe_allow_html=True)
st.caption("AI ê¸°ë°˜ íì—…ìœ„í—˜ ì˜ˆì¸¡ ë° ë§ì¶¤í˜• ì§€ì› ì‹œìŠ¤í…œ")

# -------------------- ì•ˆì „ ë¡œë” --------------------
def _try_read_csv(path: Path) -> pd.DataFrame:
    for enc in ("cp949", "euc-kr", "utf-8"):
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            pass
    try:
        txt = path.read_bytes().decode("utf-8", errors="replace")
        return pd.read_csv(io.StringIO(txt))
    except Exception:
        return pd.DataFrame()

@st.cache_data(show_spinner=False)
def load_pred() -> pd.DataFrame:
    p = FILE_PRED
    if p.suffix.lower() == ".parquet":
        return pd.read_parquet(p)
    return _try_read_csv(p)

@st.cache_data(show_spinner=False)
def load_merged() -> pd.DataFrame:
    if FILE_MERGED.exists():
        if FILE_MERGED.suffix.lower() == ".parquet":
            return pd.read_parquet(FILE_MERGED)
        return _try_read_csv(FILE_MERGED)
    return pd.DataFrame()

@st.cache_data(show_spinner=False)
def load_mapping() -> pd.DataFrame:
    if not FILE_MAPCSV.exists():
        return pd.DataFrame()
    df = _try_read_csv(FILE_MAPCSV)
    id_col  = next((c for c in df.columns if str(c).upper() in {"ENCODED_MCT","ENCODED","STORE_ID"}), None)
    nm_col  = next((c for c in df.columns if str(c).upper() in {"MCT_NM","STORE_NAME","ê°€ë§¹ì ëª…"}), None)
    bse_col = next((c for c in df.columns if "MCT_BSE" in str(c).upper()), None)
    if not id_col or not nm_col:
        return pd.DataFrame()
    m = df[[id_col, nm_col] + ([bse_col] if bse_col else [])].copy()
    m.columns = ["ENCODED_MCT","MCT_NM"] + (["MCT_BSE_AR"] if bse_col else [])
    m["ENCODED_MCT"] = m["ENCODED_MCT"].astype(str).str.strip()
    m["MCT_NM"] = m["MCT_NM"].astype(str).str.strip()
    if "MCT_BSE_AR" in m.columns:
        m["MCT_BSE_AR"] = m["MCT_BSE_AR"].astype(str).str.strip()
    return m.drop_duplicates()

@st.cache_data(show_spinner=False)
def load_alerts() -> pd.DataFrame:
    return _try_read_csv(FILE_ALERTS) if FILE_ALERTS.exists() else pd.DataFrame()

@st.cache_data(show_spinner=False)
def load_sigrec() -> pd.DataFrame:
    return _try_read_csv(FILE_SIGREC) if FILE_SIGREC.exists() else pd.DataFrame()

@st.cache_data(show_spinner=False)
def load_policy_map() -> pd.DataFrame:
    """
    ì •ì±… ë§¤í•‘ ì—‘ì…€ì„ ìœ ì—°í•˜ê²Œ ì½ì–´ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”.
    """
    if not POLICY_XLSX.exists():
        return pd.DataFrame()
    try:
        df = pd.read_excel(POLICY_XLSX)
    except Exception:
        df = pd.read_excel(POLICY_XLSX, engine="openpyxl")

    colmap = {}
    for c in df.columns:
        cu = str(c).strip().lower()
        if cu in {"policy_id","id","ì •ì±…id","pid"}: colmap[c] = "policy_id"
        elif cu in {"title","ì •ì±…ëª…","name"}: colmap[c] = "title"
        elif cu in {"owner","ê¸°ê´€","ì£¼ê´€ê¸°ê´€"}: colmap[c] = "owner"
        elif cu in {"url","link","ì‹ ì²­ë§í¬"}: colmap[c] = "url"
        elif cu in {"deadline","ë§ˆê°","ë§ˆê°ì¼"}: colmap[c] = "deadline"
        elif cu in {"support_type","ìœ í˜•","type","ì§€ì›ìœ í˜•"}: colmap[c] = "support_type"
        elif cu in {"region","ì§€ì—­","í–‰ì •ë™","ì§€ìì²´"}: colmap[c] = "region"
        elif cu in {"industry","ì—…ì¢…"}: colmap[c] = "industry"
        elif cu in {"min_risk","ìµœì†Œë“±ê¸‰","ìœ„í—˜ë“±ê¸‰"}: colmap[c] = "min_risk"
        elif cu in {"driver_tags","risk_tags","íƒœê·¸","tags"}: colmap[c] = "risk_tags"
        elif cu in {"risk_group","ìœ„í—˜êµ°","group"}: colmap[c] = "risk_group"
        elif cu in {"summary","ì„¤ëª…","ë¹„ê³ "}: colmap[c] = "summary"
    df = df.rename(columns=colmap)

    for k in ["policy_id","title","owner","url","deadline","support_type",
              "region","industry","min_risk","risk_tags","risk_group","summary"]:
        if k not in df.columns: df[k] = ""

    df["policy_id"] = df["policy_id"].astype(str).str.strip()
    df["title"] = df["title"].astype(str).str.strip()
    df["owner"] = df["owner"].astype(str).str.strip()
    df["url"] = df["url"].astype(str).str.strip()
    df["support_type"] = df["support_type"].astype(str).str.strip().str.lower()
    df["region"] = df["region"].astype(str).str.strip()
    df["industry"] = df["industry"].astype(str).str.strip()
    df["min_risk"] = df["min_risk"].astype(str).str.strip()
    # <-- ê³¼ê±° ì˜¤ë¥˜ ì§€ì : Series.lower() ë°©ì§€ ìœ„í•´ .str.lower() ì‚¬ìš©
    df["risk_group"] = df["risk_group"].astype(str).str.strip().str.lower()

    if "risk_tags" in df.columns:
        df["risk_tags"] = df["risk_tags"].astype(str).str.strip().str.lower()
    else:
        df["risk_tags"] = ""

    try:
        df["deadline"] = pd.to_datetime(df["deadline"], errors="coerce")
    except Exception:
        df["deadline"] = pd.NaT

    def _infer_support_type(row):
        t = (row.get("support_type") or "").strip().lower()
        if t:
            return t
        g = (row.get("risk_group") or "").lower()
        if any(k in g for k in ["ëŒ€ì¶œ","ê¸ˆìœµ","ë¶€ë‹´","ê¸ˆë¦¬"]): return "loan"
        if any(k in g for k in ["ë³´í—˜"]): return "insurance"
        if any(k in g for k in ["ê³ ê°","ë§ˆì¼€íŒ…","í™ë³´","íŒë¡œ"]): return "marketing"
        if any(k in g for k in ["ê³µë™êµ¬ë§¤","ì›ê°€","ì„ëŒ€","ë¹„ìš©"]): return "sourcing"
        return "policy"
    df["support_type"] = df.apply(_infer_support_type, axis=1)

    return df

def _ensure_datetime(df: pd.DataFrame, col="month"):
    if col in df.columns and not np.issubdtype(df[col].dtype, np.datetime64):
        df[col] = pd.to_datetime(df[col], errors="coerce")

# -------------------- ë°ì´í„° ì ì¬/ì •ë¦¬ --------------------
pred   = load_pred()
merged = load_merged()
mapping= load_mapping()
alerts = load_alerts()
sigrec = load_sigrec()
policy_map = load_policy_map()

for _df in (pred, merged, alerts, sigrec):
    if not _df.empty:
        _ensure_datetime(_df, "month")

# í‘œì¤€ í‚¤ ì •ë¦¬ + ì´ë¦„ ë§¤í•‘(ê°•í™”)
if "store_id" in pred.columns:
    pred["store_id"] = pred["store_id"].astype(str)

if "ENCODED_MCT" not in pred.columns and "store_id" in pred.columns:
    pred["ENCODED_MCT"] = pred["store_id"]

if not mapping.empty and {"ENCODED_MCT","MCT_NM"}.issubset(mapping.columns):
    pred = pred.merge(mapping, on="ENCODED_MCT", how="left")

# ì´ë¦„ ì •ê·œí™”
name = pred.get("MCT_NM", pd.Series(index=pred.index, dtype=object))
name = name.astype(str).str.strip().replace({"nan": "", "None": "", "NULL": "", "<NA>": ""})
pred["MCT_NM"] = np.where(name.eq(""), pred["store_id"], name)

# -------------------- ìœ í‹¸ --------------------
def latest_month(df: pd.DataFrame) -> pd.Timestamp | None:
    return pd.to_datetime(df["month"]).max() if "month" in df else None

def latest_per_store(df: pd.DataFrame) -> pd.DataFrame:
    if "month" not in df:
        return df.copy()
    idx = df.groupby("store_id", observed=False)["month"].idxmax()
    return df.loc[idx].copy()

def pct(n, d):
    try:
        return f"{100*n/d:.1f}%"
    except Exception:
        return "N/A"

def num(x):
    try:
        return f"{int(x):,}"
    except Exception:
        return "0"

def _kdict():
    return {
        "customer": "ê³ ê°ì¸µ ë³€í™”",
        "market":   "ìƒê¶Œ í˜¼ì¡Â·íì—…ë¥ ",
        "industry": "ì—…ì¢… ìœ„í—˜",
        "sales":    "ë§¤ì¶œ íë¦„",
        "macro":    "ê±°ì‹œÂ·ì„ëŒ€ë£Œ",
    }

# ---- ê·¸ë˜í”„ ì•ˆë‚´ & ì‰¬ìš´ í•´ì„ ----
def _intro_text(kind: str) -> str:
    if kind == "avg3":
        return "<div class='callout'><b>ì „ì²´ ì í¬ì˜ ì›”ë³„ í‰ê·  â€˜3ê°œì›” í›„ íì—… ìœ„í—˜ í™•ë¥ â€™</b>ì…ë‹ˆë‹¤.</div>"
    if kind == "avg6":
        return "<div class='callout'><b>ì „ì²´ ì í¬ì˜ ì›”ë³„ í‰ê·  â€˜6ê°œì›” í›„ íì—… ìœ„í—˜ í™•ë¥ â€™</b>ì…ë‹ˆë‹¤.</div>"
    if kind == "shop3":
        return "<div class='callout'>ì„ íƒí•œ ì í¬ì˜ <b>ì›”ë³„ â€˜3ê°œì›” í›„ íì—… ìœ„í—˜ í™•ë¥ â€™</b> ì¶”ì„¸ì…ë‹ˆë‹¤.</div>"
    if kind == "shop6":
        return "<div class='callout'>ì„ íƒí•œ ì í¬ì˜ <b>ì›”ë³„ â€˜6ê°œì›” í›„ íì—… ìœ„í—˜ í™•ë¥ â€™</b> ì¶”ì„¸ì…ë‹ˆë‹¤.</div>"
    return ""

def _describe_ts(months: pd.Series, values: pd.Series, scope_label: str) -> str:
    try:
        m = pd.to_datetime(months)
        v = pd.to_numeric(values, errors="coerce")
        ok = m.notna() & v.notna()
        m, v = m[ok], v[ok]
        if len(v) < 2:
            return f"<div class='caption-note'>Â· {scope_label}: ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</div>"
        last = float(v.iloc[-1]); last_m = m.iloc[-1]
        w = 3 if len(v) >= 4 else (len(v)-1)
        recent_delta = last - float(v.iloc[-(w+1)])
        idx_max = int(v.argmax()); idx_min = int(v.argmin())
        m_max, v_max = m.iloc[idx_max], float(v.iloc[idx_max])
        m_min, v_min = m.iloc[idx_min], float(v.iloc[idx_min])
        def p(x): return f"{x*100:.1f}%"
        def sign_txt(x):
            if x > 0.0001: return f"ìƒìŠ¹(+{p(x)})"
            if x < -0.0001: return f"í•˜ë½({p(x)})"
            return "í° ë³€í™” ì—†ìŒ(Â±0.0%p)"
        html = [
            f"<div class='caption-note'><b>ê·¸ë˜í”„ ìš”ì•½</b> â€” {scope_label}</div>",
            "<ul class='caption-list'>",
            f"<li><b>í˜„ì¬</b>: {last_m.strftime('%Y-%m')} ê¸°ì¤€ {p(last)} ì…ë‹ˆë‹¤.</li>",
            f"<li><b>ìµœê·¼</b>: ìµœê·¼ {w}ê°œì›” {sign_txt(recent_delta)}.</li>",
            f"<li><b>ë²”ìœ„</b>: ìµœê³  {p(v_max)}({m_max.strftime('%Y-%m')}), ìµœì € {p(v_min)}({m_min.strftime('%Y-%m')}).</li>",
            "</ul>"
        ]
        return "".join(html)
    except Exception:
        return f"<div class='caption-note'>Â· {scope_label}: í•´ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</div>"

# ------------- Gemini: í‚¤ íƒìƒ‰ + ëª¨ë¸ ì„ íƒ + í˜¸ì¶œ + ë¡œê¹… -------------
def _get_gemini_key_from_user() -> str | None:
    # secrets â†’ env â†’ session â†’ ì…ë ¥ë€
    key = None
    try:
        if hasattr(st, "secrets"):
            key = st.secrets.get("GEMINI_API_KEY", None)
    except StreamlitSecretNotFoundError:
        key = None
    if not key:
        key = os.getenv("GEMINI_API_KEY")
    if not key:
        key = st.session_state.get("GEMINI_API_KEY")
    if not key:
        with st.popover("ğŸ” Gemini API í‚¤ ì…ë ¥", use_container_width=True):
            st.caption("Â· ê¶Œì¥: .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©", unsafe_allow_html=True)
            _k = st.text_input("GEMINI_API_KEY", type="password", placeholder="AIza... ë¡œ ì‹œì‘", label_visibility="collapsed")
            if _k:
                st.session_state["GEMINI_API_KEY"] = _k.strip()
                key = _k.strip()
                st.success("í‚¤ê°€ ì„¸ì…˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return key
# --- êµì²´ ì‹œì‘: ëª¨ë¸ ì¡°íšŒ/ì„ íƒ/í˜¸ì¶œ ---

def _list_models_safe():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ (name, methods) í˜•íƒœë¡œ ë°˜í™˜.
    methodsì—ëŠ” 'generateContent' ë˜ëŠ” 'generate_content' ê°™ì€ ì§€ì› ë©”ì„œë“œ ëª©ë¡ì´ ë“¤ì–´ê°.
    """
    if not _HAS_GEMINI:
        return []
    try:
        models = []
        for m in genai.list_models():
            # google-generativeai >= 0.7.x ê¸°ì¤€
            name = getattr(m, "name", None) or getattr(m, "model", None)
            methods = set(getattr(m, "supported_generation_methods", []) or [])
            # ì¼ë¶€ ë²„ì „ì€ í•„ë“œëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ í•˜ìœ„ í˜¸í™˜
            if not methods:
                caps = getattr(m, "generation_capabilities", None)
                if isinstance(caps, dict):
                    methods = set(caps.get("methods", []))
            models.append((name, methods))
        return models
    except Exception:
        return []

def _pick_gemini_model() -> str:
    """
    generateContentë¥¼ ì§€ì›í•˜ëŠ” í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ë§Œ í›„ë³´ë¡œ.
    ìš°ì„ ìˆœìœ„: 2.5 flash > 2.5 pro > 1.5 flash > 1.5 pro > 1.0 pro
    """
    # ê¶Œì¥ ìš°ì„ ìˆœìœ„(í•­ìƒ ì „ì²´ ì´ë¦„ ì‚¬ìš©: 'models/...' ì ‘ë‘ì‚¬ í¬í•¨)
    preferred = [
        "models/gemini-2.5-flash",
        "models/gemini-2.5-pro",
        "models/gemini-1.5-flash-latest",
        "models/gemini-1.5-flash",
        "models/gemini-1.5-pro",
        "models/gemini-1.0-pro",
    ]

    avail = _list_models_safe()

    # generateContent / generate_content ì§€ì› ëª¨ë¸ë§Œ í•„í„°
    def is_text_model(methods: set) -> bool:
        methods_lower = {str(x).lower() for x in (methods or set())}
        return any(k in methods_lower for k in ("generatecontent", "generate_content"))

    text_models = [name for (name, methods) in avail if name and is_text_model(methods)]

    # 1) ì„ í˜¸ ëª©ë¡ê³¼ êµì§‘í•© ìš°ì„  ì„ íƒ
    for m in preferred:
        if m in text_models:
            return m

    # 2) ë¦¬ìŠ¤íŠ¸ ì¡°íšŒëŠ” ëì§€ë§Œ ì„ í˜¸ ëª©ë¡ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ëª¨ë¸ ì¤‘ ì²« ë²ˆì§¸
    if text_models:
        return text_models[0]

    # 3) list_models ìì²´ê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜ í…ìŠ¤íŠ¸ ëª¨ë¸ ì‹ë³„ì´ ì•ˆë˜ë©´ ì•ˆì „í•œ ëª…ì‹œ ëª¨ë¸ë¡œ
    return "models/gemini-2.5-flash"

def _gemini_generate(prompt: str) -> str:
    key = _get_gemini_key_from_user()
    if not _HAS_GEMINI:
        return "[ì„¤ì¹˜ í•„ìš”] pip install google-generativeai"
    if not key:
        return "[í‚¤ í•„ìš”] ì˜¤ë¥¸ìª½ ìƒë‹¨ 'ğŸ” Gemini API í‚¤ ì…ë ¥'ì—ì„œ í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”."
    try:
        genai.configure(api_key=key)
        model_name = _pick_gemini_model()
        model = genai.GenerativeModel(model_name=model_name)
        resp = model.generate_content(
            prompt,
            generation_config={"temperature": 0.4}  # ì•ˆì •ì  ìš”ì•½
        )
        text = (resp.text or "").strip()
        if not text:
            return f"[AI ì„¤ëª… ìƒì„± ì‹¤íŒ¨] ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤. ì‚¬ìš© ëª¨ë¸: {model_name}"
        return text
    except Exception as e:
        # ë””ë²„ê¹… íŒíŠ¸: í˜¸ì¶œ ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ ë‹¤ì‹œ ë‚˜ì—´
        avail = _list_models_safe()
        callable_models = [n for (n, m) in avail if n and any(
            k in {str(x).lower() for x in (m or set())}
            for k in ("generatecontent", "generate_content")
        )]
        hint = f"ì‚¬ìš© ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ëª¨ë¸: {', '.join(callable_models[:8])}..." if callable_models else "list_models ì‹¤íŒ¨(ê¶Œí•œ/ë„¤íŠ¸ì›Œí¬ í™•ì¸)"
        return f"[AI ì„¤ëª… ìƒì„± ì˜¤ë¥˜] {e}\níŒíŠ¸: {hint}"

# --- êµì²´ ë ---

def _save_ai_log(store_id: str, prompt: str, response: str, metrics: dict):
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    log = {
        "timestamp": datetime.datetime.now().isoformat(),
        "store_id": store_id,
        "prompt": prompt,
        "response": response,
        "metrics": metrics,
    }
    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(log, ensure_ascii=False) + "\n")

def _build_ai_context(store_name: str, store_id: str, district: str, category: str,
                      top_groups: list[str], reasons: list[str], score_now: float,
                      extra_metrics: dict) -> str:
    """
    ì„ íƒ ì í¬ í•µì‹¬ ì§€í‘œë§Œ ê¹”ë”íˆ í”„ë¡¬í”„íŠ¸ë¡œ êµ¬ì„±
    """
    lines = []
    lines.append(f"[ì í¬] ì´ë¦„: {store_name} / ID: {store_id}")
    if district or category:
        lines.append(f"[ë©”íƒ€] í–‰ì •ë™: {district or '-'} / ì—…ì¢…: {category or '-'}")
    if np.isfinite(score_now):
        lines.append(f"[í˜„ì¬ ìœ„í—˜í™•ë¥ (3M)] {score_now*100:.1f}%")
    if top_groups:
        lines.append("[ì˜í–¥ ê·¸ë£¹ Top3] " + " Â· ".join(top_groups))
    if reasons:
        lines.append("[ì›ì¸ ì‹ í˜¸] " + " / ".join([r.lstrip('- ').strip() for r in reasons]))
    if extra_metrics:
        pairs = [f"{k}: {v}" for k, v in extra_metrics.items()]
        lines.append("[ìš”ì•½ ìˆ˜ì¹˜] " + " / ".join(pairs))

    context = "\n".join(lines)
    # ì§€ì‹œì–´
    system = textwrap.dedent("""
    ì‘ì—…: ì£¼ì–´ì§„ ì í¬ ìœ„í—˜ìš”ì•½ì„ 2~3ì¤„ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    í˜•ì‹:
    - ì™œ ì•Œë¦¼ì´ ë–´ëŠ”ì§€(í•µì‹¬ ì›ì¸)
    - ì§€ê¸ˆ ì í¬ì£¼ê°€ í•  ì¼(CTA, í–‰ë™ 1~2ê°œ)
    ë¬¸ì²´: ê°„ê²°, ì‹¤í–‰ì§€í–¥, ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©.
    """).strip()
    return system + "\n\n" + context

# -------------------- íƒ­ --------------------
t_overview, t_map, t_store, t_policy = st.tabs(
    ["Overview", "Risk Map", "Store Explorer", "AI Policy Lab"]
)

# -------------------- Overview --------------------
with t_overview:
    st.markdown("### ğŸ§­ ìƒê¶Œ ìœ„í—˜ ê°œìš”")
    lm = latest_month(pred)
    latest = pred[pred["month"]==lm].copy() if lm is not None else pred.copy()

    if not pred.empty:
        any3 = latest.groupby("store_id", observed=False)["risk_label_3m"].max() if "risk_label_3m" in latest else pd.Series(dtype=int)
        any6 = latest.groupby("store_id", observed=False)["risk_label_6m"].max() if "risk_label_6m" in latest else pd.Series(dtype=int)
        total = any3.index.nunique() if len(any3) else pred["store_id"].nunique()
        high3 = int((any3==1).sum()) if len(any3) else 0
        warn6 = int(((any6==1) & ((any3!=1) if len(any3) else True)).sum()) if len(any6) else 0
    else:
        total = high3 = warn6 = 0

    c1,c2,c3,c4 = st.columns(4)
    with c1: st.metric("ì „ì²´ ì í¬ ìˆ˜", num(total))
    with c2: st.metric("3ê°œì›” ë‚´ ê³ ìœ„í—˜ ì í¬", num(high3), pct(high3, total))
    with c3: st.metric("6ê°œì›” ë‚´ ìœ„í—˜ ì í¬", num(warn6), pct(warn6, total))
    with c4:
        f1 = pred.get("f1_3m", pd.Series([np.nan])).dropna()
        auc= pred.get("auc_3m", pd.Series([np.nan])).dropna()
        txt = ("F1 " + (f"{f1.iloc[0]:.3f}" if len(f1) else "N/A"))
        if len(auc): txt += f" Â· AUC {auc.iloc[0]:.3f}"
        st.metric("ëª¨ë¸ ì„±ëŠ¥(3M)", txt)

    two = st.columns(2)
    if {"month","risk_proba_3m"}.issubset(pred.columns):
        t = pred.groupby("month", as_index=False, observed=False)["risk_proba_3m"].mean().dropna()
        two[0].markdown(_intro_text("avg3"), unsafe_allow_html=True)
        fig = px.line(t, x="month", y="risk_proba_3m", markers=True, height=360, title="ì›”ë³„ í‰ê·  ìœ„í—˜ í™•ë¥ (3ê°œì›”)")
        fig.update_layout(yaxis_title="ìœ„í—˜ í™•ë¥ (í‰ê· )", xaxis_title="ì›”")
        two[0].plotly_chart(fig, use_container_width=True)
        two[0].markdown(_describe_ts(t["month"], t["risk_proba_3m"], "ì „ì²´ í‰ê· (3ê°œì›”)"), unsafe_allow_html=True)
    if {"month","risk_proba_6m"}.issubset(pred.columns):
        t2 = pred.groupby("month", as_index=False, observed=False)["risk_proba_6m"].mean().dropna()
        two[1].markdown(_intro_text("avg6"), unsafe_allow_html=True)
        fig2 = px.line(t2, x="month", y="risk_proba_6m", markers=True, height=360, title="ì›”ë³„ í‰ê·  ìœ„í—˜ í™•ë¥ (6ê°œì›”)")
        fig2.update_layout(yaxis_title="ìœ„í—˜ í™•ë¥ (í‰ê· )", xaxis_title="ì›”")
        two[1].plotly_chart(fig2, use_container_width=True)
        two[1].markdown(_describe_ts(t2["month"], t2["risk_proba_6m"], "ì „ì²´ í‰ê· (6ê°œì›”)"), unsafe_allow_html=True)

# -------------------- Risk Map --------------------
with t_map:
    st.markdown("### ğŸ—ºï¸ Risk Map â€” ì§€ì—­ë³„ ìœ„í—˜ë„")
    geo_path = APP_DIR / "assets" / "seoul_districts.geojson"

    if pred.empty or "district" not in pred:
        st.info("district ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        g3 = pred.groupby("district", as_index=False, observed=False)["risk_proba_3m"].mean()
        g6 = pred.groupby("district", as_index=False, observed=False)["risk_proba_6m"].mean() if "risk_proba_6m" in pred else None

        if geo_path.exists():
            import json, numpy as np
            with open(geo_path, encoding="utf-8") as f:
                geojson = json.load(f)

            which = st.radio(
                "í‘œì‹œ ì§€í‘œ",
                ["3ê°œì›” ìœ„í—˜ë„(í‰ê· )"] + (["6ê°œì›” ìœ„í—˜ë„(í‰ê· )"] if g6 is not None else []),
                horizontal=True,
            )
            val_col = "risk_proba_3m" if which.startswith("3ê°œì›”") else "risk_proba_6m"
            g = g3 if val_col == "risk_proba_3m" else g6

            # âœ… ìƒ‰ ë²”ìœ„ë¥¼ ë°ì´í„°ì— ë§ê²Œ ë™ì ìœ¼ë¡œ ì„¤ì •
            vals = pd.to_numeric(g[val_col], errors="coerce")
            vmin, vmax = float(vals.min()), float(vals.max())
            if not (np.isfinite(vmin) and np.isfinite(vmax)) or vmin == vmax:
                # ì „ë¶€ ê°™ì€ ê°’ì´ê±°ë‚˜ ê²°ì¸¡ì´ë©´ ì•ˆì „í•œ ê¸°ë³¸ê°’
                vmin, vmax = 0.0, 1.0

            fig = px.choropleth_mapbox(
                g,
                geojson=geojson,
                locations="district",
                color=val_col,
                featureidkey="properties.name",
                color_continuous_scale="Reds",
                range_color=(vmin, vmax),   # â¬…ï¸ ì—¬ê¸°!
                mapbox_style="carto-positron",
                zoom=11.7,
                center={"lat": 37.547, "lon": 127.035},
                opacity=0.68,
                height=680,
                title=("í–‰ì •ë™ë³„ í‰ê·  3ê°œì›” ìœ„í—˜ë„"
                       if val_col == "risk_proba_3m"
                       else "í–‰ì •ë™ë³„ í‰ê·  6ê°œì›” ìœ„í—˜ë„"),
            )

            # íˆ´íŒ: í¬ê³  ëª…í™•í•˜ê²Œ + %í‘œì‹œ
            fig.update_traces(
                hovertemplate=(
                    "<b>í–‰ì •ë™:</b> %{location}<br>"
                    + ("<b>3ê°œì›” ìœ„í—˜ë„:</b> %{z:.1%}"
                       if val_col == "risk_proba_3m"
                       else "<b>6ê°œì›” ìœ„í—˜ë„:</b> %{z:.1%}")
                    + "<extra></extra>"
                )
            )
            fig.update_layout(
                hoverlabel=dict(
                    bgcolor="rgba(255,255,255,0.96)",
                    font_size=16,
                    font_color="black",
                    font_family="Arial",
                ),
                margin=dict(l=0, r=0, t=60, b=0),
                coloraxis_colorbar=dict(   # colorbar ì„¤ì •ì€ coloraxis_colorbarë¡œ
                    title="ìœ„í—˜ í™•ë¥ (%)",
                    tickformat=".0%",
                ),
            )

            st.plotly_chart(fig, use_container_width=True)

        else:
            st.warning("ì§€ë„ íŒŒì¼ì´ ì—†ì–´ í‘œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. `dashboard/assets/seoul_districts.geojson` ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")
            show = g3.merge(g6, on="district", how="outer") if g6 is not None else g3
            if "risk_proba_3m" in show: show["3M(%)"] = (show["risk_proba_3m"] * 100).round(1)
            if "risk_proba_6m" in show: show["6M(%)"] = (show["risk_proba_6m"] * 100).round(1)
            st.dataframe(
                show.rename(columns={"district": "í–‰ì •ë™"})[["í–‰ì •ë™"] + [c for c in ["3M(%)", "6M(%)"] if c in show]],
                use_container_width=True, height=580,
            )




# -------------------- Store Explorer (ë¦¬ë‰´ì–¼) --------------------
with t_store:
    # ====== ìŠ¤íƒ€ì¼: ì¹´ë“œ/ë°°ì§€/AIìš”ì•½ ë ˆì´ì•„ì›ƒ ======
    st.markdown("""
    <style>
    .ai-summary-card {
        background: linear-gradient(145deg, #f9fafb 0%, #eef2ff 100%);
        border-radius: 14px;
        padding: 1.1rem 1.25rem;
        margin-top: .6rem;
        box-shadow: 0 2px 10px rgba(0,0,0,.06);
        color: #111827;
        border: 1px solid rgba(99,102,241,.18);
    }
    .ai-summary-card h4 { font-size: 16px; font-weight: 800; margin: 0 0 .35rem 0; color: #4f46e5; }
    .ai-summary-text { font-size: 14.5px; line-height: 1.6; }
    .hint { font-size: 12.5px; opacity: .8; margin-top: .25rem;}
    .sec-caption { font-size: 13px; opacity: .9; margin: .1rem 0 .6rem 0;}
    </style>
    """, unsafe_allow_html=True)

    st.markdown("### ğŸª ìƒì ëª… ê¸°ë°˜ ìƒì„¸ ë¶„ì„")
    st.caption("í•„í„°ë¡œ í›„ë³´ë¥¼ ì¢íŒ í›„ ì í¬ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”. **ì„ íƒ ì í¬ì˜ ìµœì‹  ê¸°ì¤€**ìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.")

    # ---------- í•„í„° UI ----------
    c_dist, c_cat, c_shop = st.columns([1.0, 1.0, 1.4])

    with c_dist:
        dist_sel = st.multiselect(
            "í–‰ì •ë™",
            sorted(pred["district"].dropna().unique()) if "district" in pred else [],
            placeholder="í–‰ì •ë™ ì„ íƒ"
        )
    with c_cat:
        cat_sel = st.multiselect(
            "ì—…ì¢…",
            sorted(pred["category"].dropna().unique()) if "category" in pred else [],
            placeholder="ì—…ì¢… ì„ íƒ"
        )

    # ì„ íƒ ì¡°ê±´ìœ¼ë¡œ í›„ë³´ í•„í„°ë§
    cand = pred.copy()
    if dist_sel and "district" in cand: cand = cand[cand["district"].isin(dist_sel)]
    if cat_sel and "category" in cand:  cand = cand[cand["category"].isin(cat_sel)]

    # ìµœì‹  ë ˆì½”ë“œ ê¸°ì¤€ ìœ ë‹ˆí¬ ìŠ¤í† ì–´ ëª©ë¡
    cand_latest = latest_per_store(cand)

    # í‘œì‹œí•  ê°€ê²Œëª… ì—´ ê²°ì •
    name_col = "MCT_NM_mask" if "MCT_NM_mask" in cand_latest.columns else ("MCT_NM" if "MCT_NM" in cand_latest.columns else None)
    if not name_col:
        cand_latest["__tmp_name__"] = cand_latest["store_id"].astype(str)
        name_col = "__tmp_name__"

    # ë“œë¡­ë‹¤ìš´ ë¼ë²¨: "ê°€ê²Œëª… Â· í–‰ì •ë™"
    def _fmt_label(row):
        nm = str(row.get(name_col, "")).strip()
        dong = str(row.get("district", "")).strip()
        base = nm if nm else str(row.get("store_id", ""))
        return f"{base} Â· {dong}" if dong else base

    opts = cand_latest[["store_id", "district", name_col]].copy()
    opts["__label"] = opts.apply(_fmt_label, axis=1)

    # ì¤‘ë³µ ë¼ë²¨ì—” ID ê¼¬ë¦¬í‘œ
    dup = opts["__label"].duplicated(keep=False)
    if dup.any():
        opts.loc[dup, "__label"] = opts.loc[dup].apply(lambda r: f"{r['__label']} ({str(r['store_id'])[-5:]})", axis=1)

    opts = opts.sort_values("__label")
    label_to_id = dict(zip(opts["__label"], opts["store_id"].astype(str)))

    with c_shop:
        sel_label = st.selectbox(
            "ì í¬ ì„ íƒ (ê°€ê²Œëª…)",
            options=list(label_to_id.keys()),
            index=0 if len(label_to_id) else None,
            placeholder="ê°€ê²Œëª… ì„ íƒ"
        )

    if not label_to_id:
        st.warning("ì„ íƒí•œ í–‰ì •ë™/ì—…ì¢…ì— í•´ë‹¹í•˜ëŠ” ì í¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ë„“í˜€ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš” ğŸ˜Š")
        st.stop()

    sel_id = label_to_id[sel_label]
    sel_id_str = str(sel_id)

    # ì„ íƒ ì •ë³´ ì„¸ì…˜ ì €ì¥ â†’ Policy Labì—ì„œ ì‚¬ìš©
    sel_row_latest = cand_latest[cand_latest["store_id"].astype(str)==sel_id_str].iloc[0]
    st.session_state["sel_store_id"] = sel_id_str
    st.session_state["sel_district"] = str(sel_row_latest.get("district",""))
    st.session_state["sel_category"] = str(sel_row_latest.get("category",""))

    # ì„ íƒí•œ ì í¬ ì‹œê³„ì—´
    sdf = pred[pred["store_id"].astype(str) == sel_id_str].sort_values("month")
    if sdf.empty:
        st.info("ì„ íƒí•œ ì í¬ì˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì•„ì§ ì—†ì–´ìš”. ë‹¤ë¥¸ ì í¬ë¥¼ ì„ íƒí•´ ë³´ì‹¤ê¹Œìš”?")
        st.stop()

    # ì„ íƒ ì í¬ íƒ€ì´í‹€
    store_disp = str(sel_row_latest.get("MCT_NM", sel_id_str))
    st.markdown(f"#### ğŸ“ ì„ íƒ ì í¬: **{store_disp}**")
    st.markdown("<div class='sec-caption'>ì•„ë˜ ì§€í‘œëŠ” ìµœê·¼ ì›” ê¸°ì¤€ì…ë‹ˆë‹¤. ì¶”ì„¸ë¥¼ í•¨ê»˜ ë³´ë©´ì„œ ê°œì„  í¬ì¸íŠ¸ë¥¼ ì°¾ì•„ë³¼ê²Œìš”!</div>", unsafe_allow_html=True)

    # ---------- ìƒë‹¨ ìš”ì•½ ----------
    cA, cB, cC = st.columns(3)
    last = sdf.iloc[-1]
    t3 = int(last.get("risk_label_3m", 0))
    t6 = int(last.get("risk_label_6m", 0))

    with cA:
        # 3ê°œì›”: ê³ ìœ„í—˜ / ì•ˆì •
        st.markdown(
            f"**3ê°œì›” ë“±ê¸‰**  \n"
            f"<span class='badge {'badge-red' if t3==1 else 'badge-emerald'}'>"
            f"{'ê³ ìœ„í—˜' if t3==1 else 'ì•ˆì •'}</span>",
            unsafe_allow_html=True,
        )

    with cB:
        # 6ê°œì›”: t3=1ì´ë©´ 'ê³ ìœ„í—˜' ê³„ìŠ¹, ê·¸ ì™¸ t6=1ì´ë©´ 'ìœ„í—˜', ì•„ë‹ˆë©´ 'ì•ˆì •'
        tier6  = 'ê³ ìœ„í—˜' if t3==1 else ('ìœ„í—˜' if t6==1 else 'ì•ˆì •')
        color6 = 'badge-red' if tier6=='ê³ ìœ„í—˜' else ('badge-amber' if tier6=='ìœ„í—˜' else 'badge-emerald')
        st.markdown(
            f"**6ê°œì›” ë“±ê¸‰**  \n"
            f"<span class='badge {color6}'>{tier6}</span>",
            unsafe_allow_html=True,
        )

    with cC:
        r_now = float(last.get("risk_proba_3m", np.nan))
        st.metric("íì—… ìœ„í—˜ ì ìˆ˜(í˜„ì¬, 3ê°œì›”)", "N/A" if not np.isfinite(r_now) else f"{r_now*100:.1f}%")


    # ---------- ì¶”ì„¸ ê·¸ë˜í”„ ----------
    g1,g2 = st.columns(2)
    if {"month","risk_proba_3m"}.issubset(sdf.columns):
        g1.markdown(_intro_text("shop3"), unsafe_allow_html=True)
        fig = px.line(sdf, x="month", y="risk_proba_3m", markers=True, height=360, title="ì í¬ ìœ„í—˜ í™•ë¥  ì¶”ì„¸ (3ê°œì›”)")
        fig.update_layout(yaxis_title="ìœ„í—˜ í™•ë¥ (ì í¬)", xaxis_title="ì›”")
        g1.plotly_chart(fig, use_container_width=True)
        g1.markdown(_describe_ts(sdf["month"], sdf["risk_proba_3m"], "ì´ ì í¬(3ê°œì›”)"), unsafe_allow_html=True)

    if {"month","risk_proba_6m"}.issubset(sdf.columns):
        g2.markdown(_intro_text("shop6"), unsafe_allow_html=True)
        fig2 = px.line(sdf, x="month", y="risk_proba_6m", markers=True, height=360, title="ì í¬ ìœ„í—˜ í™•ë¥  ì¶”ì„¸ (6ê°œì›”)")
        fig2.update_layout(yaxis_title="ìœ„í—˜ í™•ë¥ (ì í¬)", xaxis_title="ì›”")
        g2.plotly_chart(fig2, use_container_width=True)
        g2.markdown(_describe_ts(sdf["month"], sdf["risk_proba_6m"], "ì´ ì í¬(6ê°œì›”)"), unsafe_allow_html=True)

    # -------------------- âš ï¸ íì—… ì¡°ê¸°ìœ„í—˜ ì›ì¸ ë¶„ì„ --------------------
    st.markdown("#### âš ï¸ íì—… ì¡°ê¸°ìœ„í—˜ ì›ì¸ ë¶„ì„")
    st.caption("ì•„ë˜ í•­ëª©ì€ ìµœê·¼ ë³€í™”ê°€ í° ì§€í‘œë¥¼ ëª¨ì•„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤!")

    glabel = _kdict()
    contrib_cols = [c for c in sdf.columns if c.startswith("contrib_") and c.endswith("_3m")]
    top3_groups: list[str] = []
    if contrib_cols:
        lastc = sdf.iloc[-1:][contrib_cols].T
        lastc.columns = ["val"]
        lastc["group"] = lastc.index.str.replace("contrib_","",regex=False).str.replace("_3m","",regex=False)
        top3_groups = lastc.sort_values("val", ascending=False).head(3)["group"].map(lambda g: glabel.get(g, g)).tolist()
        st.markdown("**ì˜í–¥ ê·¸ë£¹(ìµœì‹ ì›” Top3)**: " + " Â· ".join(top3_groups) if top3_groups else "_-_")
    else:
        st.markdown("<span class='small'>ê·¸ë£¹ ê¸°ì—¬ ì •ë³´ê°€ ì—†ì–´ ìƒëµí•©ë‹ˆë‹¤.</span>", unsafe_allow_html=True)

    # --- 1) ê²½ê³  ì‚¬ìœ  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    bullets: list[str] = []
    if not alerts.empty and {"store_id","month"}.issubset(alerts.columns):
        a = alerts.copy()
        a["store_id"] = a["store_id"].astype(str).str.strip()
        a = a[a["store_id"] == sel_id_str]
        if not a.empty:
            a = a.sort_values("month")
            row = a.iloc[-1]
            for key in ["reason_1","reason_2","reason_3"]:
                txt = str(row.get(key,"")).strip()
                if txt: bullets.append(f"- {txt}")

    # --- 2) í´ë°±: sigrec ê¸°ë°˜ Top3
    if not bullets and (not sigrec.empty) and {"store_id","month"}.issubset(sigrec.columns):
        s = sigrec.copy()
        s["store_id"] = s["store_id"].astype(str).str.strip()
        s = s[s["store_id"] == sel_id_str].sort_values("month")
        if not s.empty:
            last_s = s.iloc[-1]
            candidates = sorted({c[:-8] for c in s.columns if c.endswith("_delta3m")})
            scores = []
            for k in candidates:
                d = pd.to_numeric(last_s.get(f"{k}_delta3m", np.nan), errors="coerce")
                g = pd.to_numeric(last_s.get(f"{k}_peer_gap", np.nan), errors="coerce")
                if not (np.isfinite(d) or np.isfinite(g)): continue
                label_map = {
                    "youth_share":"20ëŒ€ ì´í•˜ ê³ ê° ë¹„ì¤‘", "revisit_share":"ì¬ë°©ë¬¸ ê³ ê° ë¹„ì¤‘",
                    "new_share":"ì‹ ê·œ ê³ ê° ë¹„ì¤‘", "delivery_ratio":"ë°°ë‹¬ ë§¤ì¶œ ë¹„ì¤‘",
                    "peer_sales_ratio":"ë™ì¼ ì—…ì¢… ë§¤ì¶œ ë¹„ìœ¨(=100)", "peer_trx_ratio":"ë™ì¼ ì—…ì¢… ë§¤ì¶œê±´ìˆ˜ ë¹„ìœ¨(=100)",
                    "industry_rank_pct":"ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„%", "zone_rank_pct":"ìƒê¶Œ ë‚´ ë§¤ì¶œ ìˆœìœ„%",
                    "industry_close_ratio":"ì—…ì¢… ë‚´ í•´ì§€ ê°€ë§¹ì  ë¹„ì¤‘", "zone_close_ratio":"ìƒê¶Œ ë‚´ í•´ì§€ ê°€ë§¹ì  ë¹„ì¤‘",
                    "resident_share":"ê±°ì£¼ ê³ ê° ë¹„ìœ¨", "worker_share":"ì§ì¥ ê³ ê° ë¹„ìœ¨", "floating_share":"ìœ ë™ ê³ ê° ë¹„ìœ¨",
                }
                negative_is_bad = {"industry_rank_pct","zone_rank_pct","industry_close_ratio","zone_close_ratio"}
                higher_is_better = k not in negative_is_bad
                sign = -1.0 if higher_is_better else +1.0
                score = np.nanmean([sign*(d if np.isfinite(d) else 0.0), sign*(g if np.isfinite(g) else 0.0)])
                scores.append((k, score, d, g, higher_is_better, label_map.get(k, k)))
            scores.sort(key=lambda x: (x[1] if np.isfinite(x[1]) else -1e18), reverse=True)
            for k,_, d,g,good,lab in scores[:3]:
                if good:
                    txt = f"{lab} í•˜ë½(ìµœê·¼ 3ê°œì›” Î” {d:+.2f}), í–‰ì •ë™Â·ì—…ì¢… ë™ì›” í‰ê·  ëŒ€ë¹„ {g:+.2f}%p"
                else:
                    txt = f"{lab} ìƒìŠ¹(ìµœê·¼ 3ê°œì›” Î” {d:+.2f}), í–‰ì •ë™Â·ì—…ì¢… ë™ì›” í‰ê·  ëŒ€ë¹„ {g:+.2f}%p"
                bullets.append(f"- {txt}")

    if bullets:
        st.markdown("**ğŸ“Œ ì²´í¬ í¬ì¸íŠ¸**")
        st.markdown("\n".join(bullets))
    else:
        st.info("ì„¤ëª…ì— í™œìš© ê°€ëŠ¥í•œ ì‹ í˜¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (alerts/sigrec íŒŒì¼ ë˜ëŠ” ê´€ë ¨ ì»¬ëŸ¼ ìƒì„± í•„ìš”)")

    # -------------------- AI ì„¤ëª… í† ê¸€ + Gemini í˜¸ì¶œ + ë¡œê¹… --------------------
    col_ai1, _ = st.columns([1, 3])

    try:
        ai_toggle = col_ai1.toggle("AI ì„¤ëª… ì¼œê¸° ğŸ”", value=False)
    except Exception:
        ai_toggle = col_ai1.checkbox("AI ì„¤ëª… ì¼œê¸° ğŸ”", value=False)

    # (í†¤ ìˆœí™”: ê³¼ë„í•œ ë¶€ì •ì–´ë¥¼ ì¡°ê¸ˆ ë¶€ë“œëŸ½ê²Œ ì¹˜í™˜)
    def _friendly_tone(text: str) -> str:
        rep = {
            "ì•…í™”": "ì•„ì‰¬ìš´ íë¦„", "ê¸‰ê°": "í° ì¡°ì •", "ê°ì†Œ": "ì¡°ì •", "í•˜ë½": "ì¡°ì •",
            "ë¬¸ì œ": "ê³¼ì œ", "ìœ„í—˜": "ìœ„í—˜"  # 'ìœ„í—˜'ì€ ë“±ê¸‰ í‘œê¸°ì— ì“°ë¯€ë¡œ ìœ ì§€
        }
        for a,b in rep.items():
            text = text.replace(a,b)
        return text

    # ë¬¸ì¥ ë¶„í•  â†’ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸
    def _to_bullets(text: str, max_items: int = 4) -> list[str]:
        if not text:
            return []
        parts = []
        for seg in text.replace("â€¢", "\n").replace("Â·", "\n").split("\n"):
            seg = seg.strip(" -â€¢Â·\t")
            if not seg:
                continue
            for s in seg.split(". "):
                s = s.strip(" -â€¢Â·\t.")
                if s:
                    parts.append(s)
        return parts[:max_items]

    # === âœ… í•µì‹¬ ë³€ê²½: í† ê¸€ ë°”ë¡œ ì•„ë˜ì— AI ìš”ì•½ í‘œì‹œ ===
    if ai_toggle:
        # (ì„ íƒ) í‚¤ ì…ë ¥ UI
        if _HAS_GEMINI:
            _ = _get_gemini_key_from_user()

        # í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        store_name = str(sel_row_latest.get("MCT_NM", sel_id_str))
        district = st.session_state.get("sel_district", "")
        category = st.session_state.get("sel_category", "")

        # ìµœê·¼ 3ê°œì›” ìœ„í—˜í™•ë¥  ë³€í™”
        sdf_local = sdf[["month", "risk_proba_3m"]].dropna()
        recent_delta = np.nan
        if len(sdf_local) >= 2:
            w = 3 if len(sdf_local) >= 4 else (len(sdf_local) - 1)
            recent_delta = float(
                sdf_local["risk_proba_3m"].iloc[-1]
                - sdf_local["risk_proba_3m"].iloc[-(w + 1)]
            )
        extra_metrics = {}
        if np.isfinite(r_now):
            extra_metrics["ìœ„í—˜í™•ë¥ _í˜„ì¬(3M)"] = f"{r_now*100:.1f}%"
        if np.isfinite(recent_delta):
            extra_metrics["ìµœê·¼ë³€í™”(3M)"] = f"{recent_delta*100:+.1f}%p"

        prompt = _build_ai_context(
            store_name=store_name,
            store_id=sel_id_str,
            district=district,
            category=category,
            top_groups=top3_groups,
            reasons=bullets,
            score_now=r_now if np.isfinite(r_now) else np.nan,
            extra_metrics=extra_metrics,
        )

        # âœ¨ í† ê¸€ ì•„ë˜ ì¦‰ì‹œ AI ìš”ì•½ í‘œì‹œ
        with st.spinner("AIê°€ ì í¬ ìƒí™©ì„ ì •ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            ai_text = _gemini_generate(prompt)
            ai_text = _friendly_tone(ai_text)

        st.markdown("**âœ¨ AI ìš”ì•½**")
        items = _to_bullets(ai_text, max_items=3)

        if items:
            st.markdown(
                "<ul style='margin-top:0.4rem; line-height:1.6;'>"
                + "".join(f"<li>{it}</li>" for it in items)
                + "</ul>",
                unsafe_allow_html=True,
            )
        else:
            st.caption("ìƒì„±ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")


        # ë¡œê·¸ ì €ì¥
        _save_ai_log(sel_id_str, prompt, ai_text, extra_metrics)



# -------------------- AI Policy Lab --------------------
with t_policy:
    st.markdown("### ğŸ’¡ AI Policy Lab â€” ìœ„í—˜ìœ í˜•ë³„ ë§ì¶¤ ì•¡ì…˜ & ì •ì±… ì¶”ì²œ")

    if pred.empty:
        st.info("ì˜ˆì¸¡ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    # ---------- Store Explorerì™€ ë™ì¼í•œ ìƒë‹¨ ë“œë¡­ë‹¤ìš´ ----------
    st.markdown("##### ì í¬ ì„ íƒ")
    c_dist2, c_cat2, c_shop2 = st.columns([1.0, 1.0, 1.4])

    with c_dist2:
        dist_sel2 = st.multiselect(
            "í–‰ì •ë™",
            sorted(pred["district"].dropna().unique()) if "district" in pred else [],
            default=[st.session_state.get("sel_district","")] if st.session_state.get("sel_district") else None,
            placeholder="í–‰ì •ë™ ì„ íƒ"
        )

    with c_cat2:
        cat_sel2 = st.multiselect(
            "ì—…ì¢…",
            sorted(pred["category"].dropna().unique()) if "category" in pred else [],
            default=[st.session_state.get("sel_category","")] if st.session_state.get("sel_category") else None,
            placeholder="ì—…ì¢… ì„ íƒ"
        )

    cand2 = pred.copy()
    if dist_sel2 and "district" in cand2:
        cand2 = cand2[cand2["district"].isin(dist_sel2)]
    if cat_sel2 and "category" in cand2:
        cand2 = cand2[cand2["category"].isin(cat_sel2)]

    cand2_latest = latest_per_store(cand2)

    name_col2 = "MCT_NM_mask" if "MCT_NM_mask" in cand2_latest.columns else ("MCT_NM" if "MCT_NM" in cand2_latest.columns else None)
    if not name_col2:
        cand2_latest["__tmp_name__"] = cand2_latest["store_id"].astype(str)
        name_col2 = "__tmp_name__"

    def _fmt_label2(row):
        nm = str(row.get(name_col2, "")).strip()
        dong = str(row.get("district", "")).strip()
        base = nm if nm else str(row.get("store_id", ""))
        return f"{base} Â· {dong}" if dong else base

    opts2 = cand2_latest[["store_id","district",name_col2]].copy()
    opts2["__label"] = opts2.apply(_fmt_label2, axis=1)
    dup2 = opts2["__label"].duplicated(keep=False)
    if dup2.any():
        opts2.loc[dup2, "__label"] = opts2.loc[dup2].apply(
            lambda r: f"{r['__label']} ({str(r['store_id'])[-5:]})", axis=1
        )
    opts2 = opts2.sort_values("__label")
    label_to_id2 = dict(zip(opts2["__label"], opts2["store_id"].astype(str)))

    default_index = 0
    if st.session_state.get("sel_store_id") and label_to_id2:
        try:
            default_index = list(label_to_id2.values()).index(st.session_state["sel_store_id"])
        except ValueError:
            default_index = 0

    with c_shop2:
        sel_label2 = st.selectbox(
            "ì í¬ ì„ íƒ (ê°€ê²Œëª…)",
            options=list(label_to_id2.keys()),
            index=default_index if len(label_to_id2) else None,
            placeholder="ê°€ê²Œëª… ì„ íƒ"
        )

    if not label_to_id2:
        st.warning("ì„ íƒí•œ í–‰ì •ë™/ì—…ì¢…ì— í•´ë‹¹í•˜ëŠ” ì í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_id2 = label_to_id2[sel_label2]
    sel_id_str2 = str(sel_id2)

    # ì„ íƒ ì •ë³´ ì—…ë°ì´íŠ¸(ì„¸ì…˜)
    row_latest2 = cand2_latest[cand2_latest["store_id"].astype(str)==sel_id_str2].iloc[0]
    district   = str(row_latest2.get("district",""))
    category   = str(row_latest2.get("category",""))
    _last_line2 = pred[pred["store_id"].astype(str)==sel_id_str2].sort_values("month").iloc[-1]
    risk_tier  = str(_last_line2.get("risk_tier","ì•ˆì •"))
    st.session_state["sel_store_id"] = sel_id_str2
    st.session_state["sel_district"] = district
    st.session_state["sel_category"] = category
    st.session_state["sel_risk_tier"] = risk_tier

    # ---------- ì„ íƒ ì í¬ ë°ì´í„° ----------
    sdf2 = pred[pred["store_id"].astype(str) == sel_id_str2].sort_values("month")
    if sdf2.empty:
        st.info("ì„ íƒí•œ ì í¬ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ê°„ë‹¨ ë©”íŠ¸ë¦­
    c1, c2, c3 = st.columns(3)
    c1.metric("í˜„ì¬ ë“±ê¸‰", risk_tier)
    c2.metric("í–‰ì •ë™", district if district else "-")
    c3.metric("ì—…ì¢…", category if category else "-")

    # ---------- ì •ì±…/ì•¡ì…˜ ì¶”ì²œ ----------
    tabs = st.tabs(["ì •ì±… ì¶”ì²œ", "ê¸ˆìœµ/ë³´í—˜ ì œì•ˆ", "ë§ˆì¼€íŒ…/ê³ ê°í™•ì¥", "ê³µë™êµ¬ë§¤/ì›ê°€ì ˆê°"])

    if policy_map.empty:
        for t in tabs:
            with t:
                st.info("ì •ì±… ë§¤í•‘ íŒŒì¼ì´ ì—†ì–´ ë°ëª¨ ì¹´ë“œë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤. `outputs/ì •ì±…ì§€ì›ê´€ë ¨ë§¤í•‘_251022.xlsx` ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")
    else:
        def show_cards(df):
            if df.empty:
                st.info("ì¶”ì²œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            top = df.head(8)
            for _, r in top.iterrows():
                with st.container(border=True):
                    st.markdown(f"**{r.get('title','(ë¬´ì œ)')}**  \n"
                                f"<span class='small'>{r.get('owner','')}</span>", unsafe_allow_html=True)
                    if str(r.get("summary","")).strip():
                        st.caption(str(r.get("summary","")).strip())
                    cols = st.columns(4)
                    cols[0].write(f"ìœ í˜•: **{r.get('support_type','-')}**")
                    cols[1].write(f"ì§€ì—­: **{r.get('region','-')}**")
                    cols[2].write(f"ì—…ì¢…: **{r.get('industry','-')}**")
                    ddl = r.get("deadline")
                    cols[3].write(f"ë§ˆê°: **{ddl.date() if pd.notna(ddl) else 'ìƒì‹œ'}**")
                    url = str(r.get("url","")).strip()
                    if url:
                        st.link_button("ì‹ ì²­/ì•ˆë‚´ ë°”ë¡œê°€ê¸°", url)

        with tabs[0]:
            st.subheader("ì •ë¶€/ì§€ìì²´ ì •ì±… ì¶”ì²œ")
            show_cards(policy_map[policy_map["support_type"].isin(
                ["policy","grant","advisory","subsidy","gov","public"]
            )])

        with tabs[1]:
            st.subheader("ê¸ˆìœµ/ë³´í—˜ ì œì•ˆ")
            show_cards(policy_map[policy_map["support_type"].isin(
                ["loan","credit","bnpl","insurance","fintech"]
            )])

        with tabs[2]:
            st.subheader("ë§ˆì¼€íŒ…/ê³ ê°í™•ì¥")
            show_cards(policy_map[policy_map["support_type"].isin(
                ["marketing","coupon","ad","growth"]
            )])

        with tabs[3]:
            st.subheader("ê³µë™êµ¬ë§¤/ì›ê°€ì ˆê°")
            show_cards(policy_map[policy_map["support_type"].isin(
                ["sourcing","procurement","costdown","rent"]
            )])


